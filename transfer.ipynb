{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fbc34e2",
   "metadata": {},
   "source": [
    "### Import a pretrained model\n",
    "\n",
    "Load vgg19 architecture, with its <b> pretrained weights </b> using torchvision's models module. These are the weights coming from the training using ImageNet dataset with 1000 classes like in LSVRC competition. There are various models provided in https://pytorch.org/vision/0.8/models.html with pretrained weights, I suggest you to take a look!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0723b4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [1, 64, 224, 224]           1,792\n",
      "              ReLU-2          [1, 64, 224, 224]               0\n",
      "            Conv2d-3          [1, 64, 224, 224]          36,928\n",
      "              ReLU-4          [1, 64, 224, 224]               0\n",
      "         MaxPool2d-5          [1, 64, 112, 112]               0\n",
      "            Conv2d-6         [1, 128, 112, 112]          73,856\n",
      "              ReLU-7         [1, 128, 112, 112]               0\n",
      "            Conv2d-8         [1, 128, 112, 112]         147,584\n",
      "              ReLU-9         [1, 128, 112, 112]               0\n",
      "        MaxPool2d-10           [1, 128, 56, 56]               0\n",
      "           Conv2d-11           [1, 256, 56, 56]         295,168\n",
      "             ReLU-12           [1, 256, 56, 56]               0\n",
      "           Conv2d-13           [1, 256, 56, 56]         590,080\n",
      "             ReLU-14           [1, 256, 56, 56]               0\n",
      "           Conv2d-15           [1, 256, 56, 56]         590,080\n",
      "             ReLU-16           [1, 256, 56, 56]               0\n",
      "           Conv2d-17           [1, 256, 56, 56]         590,080\n",
      "             ReLU-18           [1, 256, 56, 56]               0\n",
      "        MaxPool2d-19           [1, 256, 28, 28]               0\n",
      "           Conv2d-20           [1, 512, 28, 28]       1,180,160\n",
      "             ReLU-21           [1, 512, 28, 28]               0\n",
      "           Conv2d-22           [1, 512, 28, 28]       2,359,808\n",
      "             ReLU-23           [1, 512, 28, 28]               0\n",
      "           Conv2d-24           [1, 512, 28, 28]       2,359,808\n",
      "             ReLU-25           [1, 512, 28, 28]               0\n",
      "           Conv2d-26           [1, 512, 28, 28]       2,359,808\n",
      "             ReLU-27           [1, 512, 28, 28]               0\n",
      "        MaxPool2d-28           [1, 512, 14, 14]               0\n",
      "           Conv2d-29           [1, 512, 14, 14]       2,359,808\n",
      "             ReLU-30           [1, 512, 14, 14]               0\n",
      "           Conv2d-31           [1, 512, 14, 14]       2,359,808\n",
      "             ReLU-32           [1, 512, 14, 14]               0\n",
      "           Conv2d-33           [1, 512, 14, 14]       2,359,808\n",
      "             ReLU-34           [1, 512, 14, 14]               0\n",
      "           Conv2d-35           [1, 512, 14, 14]       2,359,808\n",
      "             ReLU-36           [1, 512, 14, 14]               0\n",
      "        MaxPool2d-37             [1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-38             [1, 512, 7, 7]               0\n",
      "           Linear-39                  [1, 4096]     102,764,544\n",
      "             ReLU-40                  [1, 4096]               0\n",
      "          Dropout-41                  [1, 4096]               0\n",
      "           Linear-42                  [1, 4096]      16,781,312\n",
      "             ReLU-43                  [1, 4096]               0\n",
      "          Dropout-44                  [1, 4096]               0\n",
      "           Linear-45                  [1, 1000]       4,097,000\n",
      "================================================================\n",
      "Total params: 143,667,240\n",
      "Trainable params: 143,667,240\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 238.69\n",
      "Params size (MB): 548.05\n",
      "Estimated Total Size (MB): 787.31\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "\n",
    "model = models.vgg19(pretrained=True)\n",
    "            \n",
    "summary(model, input_size = (3, 224, 224), batch_size = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8539cad",
   "metadata": {},
   "source": [
    "### Freeze the layers\n",
    "\n",
    "\n",
    "As mentioned, you can keep these pretrained weights without updating them during your own train, or you may prefer to include them also to your back propagation process. Below code freeze the pretrained layers, so we choose not to update these weights during training. If you change as ``` param.requires_grad = True ``` <u> you declare that you want gradient calculation for these layers </u>, these layers will be included to the backpropagation also. When we print the model summary after freezing the layers, we see that now all the parameters we have are in <b> non-trainable params </b> category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b7ac9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [1, 64, 224, 224]           1,792\n",
      "              ReLU-2          [1, 64, 224, 224]               0\n",
      "            Conv2d-3          [1, 64, 224, 224]          36,928\n",
      "              ReLU-4          [1, 64, 224, 224]               0\n",
      "         MaxPool2d-5          [1, 64, 112, 112]               0\n",
      "            Conv2d-6         [1, 128, 112, 112]          73,856\n",
      "              ReLU-7         [1, 128, 112, 112]               0\n",
      "            Conv2d-8         [1, 128, 112, 112]         147,584\n",
      "              ReLU-9         [1, 128, 112, 112]               0\n",
      "        MaxPool2d-10           [1, 128, 56, 56]               0\n",
      "           Conv2d-11           [1, 256, 56, 56]         295,168\n",
      "             ReLU-12           [1, 256, 56, 56]               0\n",
      "           Conv2d-13           [1, 256, 56, 56]         590,080\n",
      "             ReLU-14           [1, 256, 56, 56]               0\n",
      "           Conv2d-15           [1, 256, 56, 56]         590,080\n",
      "             ReLU-16           [1, 256, 56, 56]               0\n",
      "           Conv2d-17           [1, 256, 56, 56]         590,080\n",
      "             ReLU-18           [1, 256, 56, 56]               0\n",
      "        MaxPool2d-19           [1, 256, 28, 28]               0\n",
      "           Conv2d-20           [1, 512, 28, 28]       1,180,160\n",
      "             ReLU-21           [1, 512, 28, 28]               0\n",
      "           Conv2d-22           [1, 512, 28, 28]       2,359,808\n",
      "             ReLU-23           [1, 512, 28, 28]               0\n",
      "           Conv2d-24           [1, 512, 28, 28]       2,359,808\n",
      "             ReLU-25           [1, 512, 28, 28]               0\n",
      "           Conv2d-26           [1, 512, 28, 28]       2,359,808\n",
      "             ReLU-27           [1, 512, 28, 28]               0\n",
      "        MaxPool2d-28           [1, 512, 14, 14]               0\n",
      "           Conv2d-29           [1, 512, 14, 14]       2,359,808\n",
      "             ReLU-30           [1, 512, 14, 14]               0\n",
      "           Conv2d-31           [1, 512, 14, 14]       2,359,808\n",
      "             ReLU-32           [1, 512, 14, 14]               0\n",
      "           Conv2d-33           [1, 512, 14, 14]       2,359,808\n",
      "             ReLU-34           [1, 512, 14, 14]               0\n",
      "           Conv2d-35           [1, 512, 14, 14]       2,359,808\n",
      "             ReLU-36           [1, 512, 14, 14]               0\n",
      "        MaxPool2d-37             [1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-38             [1, 512, 7, 7]               0\n",
      "           Linear-39                  [1, 4096]     102,764,544\n",
      "             ReLU-40                  [1, 4096]               0\n",
      "          Dropout-41                  [1, 4096]               0\n",
      "           Linear-42                  [1, 4096]      16,781,312\n",
      "             ReLU-43                  [1, 4096]               0\n",
      "          Dropout-44                  [1, 4096]               0\n",
      "           Linear-45                  [1, 1000]       4,097,000\n",
      "================================================================\n",
      "Total params: 143,667,240\n",
      "Trainable params: 0\n",
      "Non-trainable params: 143,667,240\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 238.69\n",
      "Params size (MB): 548.05\n",
      "Estimated Total Size (MB): 787.31\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "   param.requires_grad = False\n",
    "\n",
    "summary(model, input_size = (3, 224, 224), batch_size = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d892360",
   "metadata": {},
   "source": [
    "### Modify Last Layer\n",
    "\n",
    "Now you have a prepared model for 1000 classes with its weights, but you need a model for 3 classes. So you have to update your output layer right? We can simply remove the last layer containing 1000 nodes and add a new one with 3 classes. Another approach would be not to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2a72b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Dropout(p=0.5, inplace=False)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace=True)\n",
      "  (5): Dropout(p=0.5, inplace=False)\n",
      "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model.classifier) # check model HEAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edeea455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Dropout(p=0.5, inplace=False)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace=True)\n",
      "  (5): Dropout(p=0.5, inplace=False)\n",
      "  (6): Linear(in_features=4096, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "nb_classes = 3\n",
    "\n",
    "number_features = model.classifier[-1].in_features  # obtain input node amount for the new layer\n",
    "features = list(model.classifier.children())[:-1]   # Remove last layer by putting -1 to range index, \n",
    "                                                    # So we obtain the HEAD layers' list witohut the last layer\n",
    "features.extend([torch.nn.Linear(number_features, nb_classes)]) # We extend this list with the output layer we want to add\n",
    "model.classifier = torch.nn.Sequential(*features) # replace new classifier HEAD with the old one\n",
    "\n",
    "print(model.classifier) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
